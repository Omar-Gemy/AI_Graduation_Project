{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4b577b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np # We'll use numpy to inspect the shape of our embeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68e6c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    This function takes the path to a PDF file and returns its entire text content.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        document = fitz.open(pdf_path)\n",
    "        \n",
    "        full_text = \"\"\n",
    "        \n",
    "        for page_num in range(len(document)):\n",
    "            page = document.load_page(page_num)\n",
    "            full_text += page.get_text()\n",
    "            \n",
    "        return full_text\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred while reading the file: {e}\"\n",
    "\n",
    "\n",
    "file_name = input (\"enter the path to the PDF file: \")\n",
    "\n",
    "print(f\"Extracting text from file: {file_name}...\")\n",
    "\n",
    "content = extract_text_from_pdf(file_name)\n",
    "\n",
    "print(\"---------- Start of Content ----------\")\n",
    "print(content)\n",
    "print(\"---------- End of Content ----------\")\n",
    "print(\"\\nProcess completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d067bcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=100,\n",
    "    length_function=len\n",
    ")\n",
    "text_chunks = text_splitter.split_text(content)\n",
    "\n",
    "print(f\"The text has been split into {len(text_chunks)} chunks.\")\n",
    "print(\"\\n--- Example of the first chunk: ---\\n\")\n",
    "print(text_chunks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d181f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading the embedding model...\")\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "print(\"Model loaded successfully.\")\n",
    "\n",
    "print(\"Generating embeddings for all text chunks...\")\n",
    "embeddings = model.encode(text_chunks)\n",
    "print(\"Embeddings generated successfully.\")\n",
    "\n",
    "print(f\"\\nShape of our embeddings matrix: {np.shape(embeddings)}\")\n",
    "print(f\"Number of text chunks: {len(text_chunks)}\")\n",
    "print(f\"Dimension of each embedding vector: {len(embeddings[0])}\")\n",
    "\n",
    "print(\"\\n--- Example of the first embedding vector (first 5 values): ---\")\n",
    "print(embeddings[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76775b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting to build the FAISS vector store... This might take a moment.\")\n",
    "\n",
    "embedding_function = HuggingFaceEmbeddings(model_name='all-MiniLM-L6-v2') \n",
    "vector_store = FAISS.from_texts(texts=text_chunks, embedding=embedding_function) \n",
    "print(\"Vector store has been built successfully in memory!\")\n",
    "\n",
    "VECTOR_STORE_PATH = \"faiss_index\"\n",
    "vector_store.save_local(VECTOR_STORE_PATH)\n",
    "\n",
    "print(f\"Vector store has been saved locally to the '{VECTOR_STORE_PATH}' folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea6ee0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 5}) \n",
    "\n",
    "query = input(\"Enter your question : \")\n",
    "print(f\"Searching for relevant documents for: \\\"{query}\\\"\\n\")\n",
    "relevant_docs = retriever.get_relevant_documents(query)\n",
    "\n",
    "print(\"--- Found the following relevant documents (Top 5): ---\\n\")\n",
    "for i, doc in enumerate(relevant_docs):\n",
    "    print(f\"--- Document {i+1} ---\\n\")\n",
    "    print(doc.page_content)\n",
    "    print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "\n",
    "print(\"--- Project Complete: Semantic Retrieval Successful! ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
